{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alhichri/SSDAN/blob/main/main_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdRJHTKRliFf"
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "!pip install MulticoreTSNE\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable,function\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgvQ88iQdfqR",
        "outputId": "738427a8-7b84-4208-f17e-d059e292f3dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive' , force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BeoPwz7ZEno"
      },
      "source": [
        "#####################################################\n",
        "# Define paths and parameters\n",
        "#####################################################\n",
        "\n",
        "main_folder_path = '/content/gdrive/MyDrive/'\n",
        "SSDAN_path = '/content/gdrive/MyDrive/code/SSDAN/'\n",
        "\n",
        "datasets_path = main_folder_path+'datasets/our_datasets/'\n",
        "import os\n",
        "print('Contents of folder: ', datasets_path)\n",
        "os.listdir(datasets_path) # returns list\n",
        "\n",
        "# set arguments here\n",
        "\n",
        "args_method = 'MME'; # choices=['S+T', 'ENT', 'MME']   help='MME is proposed method, ENT is entropy minimization,'\n",
        "\n",
        "args_epochs = 5001     # maximum number of training epochs \n",
        "args_batchsize = 8     # batch size for dividing the training data during training\n",
        "args_lr = 0.001      # help='learning rate (default: 0.001)'\n",
        "args_multi = 0.1      #   help='learning rate multiplication'\n",
        "args_T = 0.05     #   help='temperature (default: 0.05)'\n",
        "args_lamda =  0.1     #help='value of lamda parameters'\n",
        "args_save_check = False  #  help='save checkpoint or not'\n",
        "args_checkpath = SSDAN_path+'outputsAndPlots'   # help='dir to save checkpoint'\n",
        "args_seed = 2021                    # help='random seed (default: 1)'\n",
        "\n",
        "args_log_interval = 50          # help='how many batches to wait before logging '  'training status'\n",
        "args_net  = 'EfficientNetBase'          # choices=['resnet34', 'alexnet', 'vgg' ,'EfficientNetBase']   help='which network to use'\n",
        "\n",
        "args_dataset   =  'TWO-SOURCE'        #  choices=['THREE-SOURCE', 'TWO-SOURCE']  help='how many source datasets'\n",
        "                             # we will change this to choices=['UCMerced', 'AID', 'NWPU', 'PatternNet']  help='the name of dataset'\n",
        "args_source  = 'AID_NWPU_RESISC45'            #   help='source domain' we will change this to choices=['UCMerced', 'AID', 'NWPU',\n",
        "                                                   # 'AID_UCMerced' ,'UCMerced_NWPU_RESISC45', 'AID_NWPU_RESISC45',\n",
        "                                                   # 'AID_NWPU_RESISC45_PatternNet', 'AID_NWPU_RESISC45_UCMerced', 'AID_UCMerced_PatternNet'\n",
        "                                                   #, 'UCMerced_NWPU_RESISC45_PatternNet']\n",
        "args_target  = 'UCMerced'         #  help='target domain' , 'UCMerced', 'AID', 'NWPU'\n",
        "args_num  = 3                    #  help='number of labeled examples in the target'\n",
        "args_early  = True                  #    help='early stopping on validation or not'\n",
        "args_patience  = 5               # help='early stopping to wait for improvment '  'before terminating. (default: 5 (5000 iterations))')\n",
        "blocks_args = 3\n",
        "\n",
        "print('Dataset: %s Source: %s Target: %s Labeled num perclass: %s Network: %s' %\n",
        "      (args_dataset, args_source, args_target, args_num, args_net))\n",
        "#######################  One source  #######################\n",
        "#source_path = datasets_path+'%s/' % args_dataset  + 'NWPU_RESISC45/'\n",
        "#source_path = datasets_path+'%s/' % args_dataset  + 'AID/'\n",
        "#source_path = datasets_path+'%s/' % args_dataset  + 'UCMerced/'\n",
        "#######################  Two source  #######################\n",
        "# source_path = datasets_path+'%s/' % args_dataset  + 'AID_UCMerced/'\n",
        "# source_path = datasets_path+'%s/' % args_dataset  + 'UCMerced_NWPU_RESISC45/'\n",
        "source_path = datasets_path+'%s/' % args_dataset  + 'AID_NWPU_RESISC45/'\n",
        "#######################  Three source  #######################\n",
        "#source_path = datasets_path+'%s/' % args_dataset  + 'AID_NWPU_RESISC45_PatternNet/'\n",
        "#source_path = datasets_path+'%s/' % args_dataset  + 'AID_NWPU_RESISC45_UCMerced/'\n",
        "#source_path = datasets_path+'%s/' % args_dataset  + 'AID_UCMerced_PatternNet/'\n",
        "#source_path = datasets_path+'%s/' % args_dataset  + 'UCMerced_NWPU_RESISC45_PatternNet/'\n",
        "print('Source dataset path: ', source_path)\n",
        " \n",
        "target_path = datasets_path+'%s/' % args_dataset  + 'UCMerced/'\n",
        "# target_path = datasets_path+'%s/' % args_dataset  + 'NWPU_RESISC45/'\n",
        "# target_path = datasets_path+'%s/' % args_dataset  + 'AID/'\n",
        "#target_path = datasets_path+'%s/' % args_dataset  + 'PatternNet/'\n",
        "print('Target dataset path: ', target_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_4OHyL17Pux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079ab0f5-84c2-4091-d8d9-05496ccd9899"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: TWO-SOURCE Source: AID_UCMerced Target: NWPU Labeled num perclass: 3 Network: EfficientNetBase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8uN1ERKPS7R"
      },
      "source": [
        "from importlib.machinery import SourceFileLoader\n",
        "from importlib.util import spec_from_loader, module_from_spec\n",
        "\n",
        "somemodule = SourceFileLoader('utils', SSDAN_path+'utils/utils.py').load_module()\n",
        "from utils import weights_init, efficientnet\n",
        "\n",
        "somemodule = SourceFileLoader('loss', SSDAN_path+'utils/loss.py').load_module()\n",
        "from loss import entropy, adentropy\n",
        "\n",
        "somemodule = SourceFileLoader('lr_schedule', SSDAN_path+'utils/lr_schedule.py').load_module()\n",
        "from lr_schedule import inv_lr_scheduler\n",
        "\n",
        "#somemodule = SourceFileLoader('return_dataset', SSDAN_path+'utils/return_dataset.py').load_module()\n",
        "#from return_dataset import return_dataset\n",
        "\n",
        "somemodule = SourceFileLoader('EfficientNet', SSDAN_path+'model/EfficientNet.py').load_module()\n",
        "from EfficientNet import EfficientNetBase\n",
        "\n",
        "somemodule = SourceFileLoader('basenet', SSDAN_path+'model/basenet.py').load_module()\n",
        "from basenet import AlexNetBase, VGGBase, Predictor, Predictor_deep\n",
        "\n",
        "somemodule = SourceFileLoader('resnet', SSDAN_path+'model/resnet.py').load_module()\n",
        "from resnet import resnet34\n",
        "\n",
        "somemodule = SourceFileLoader('data_list', SSDAN_path+'loaders/data_list.py').load_module()\n",
        "from data_list import Imagelists_VISDA, return_classlist\n",
        "\n",
        "\n",
        "somemodule = SourceFileLoader('tsne_torch', SSDAN_path+'tsne_torch.py').load_module()\n",
        "from tsne_torch import tsne\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCqWBWNQnhxI"
      },
      "source": [
        "################################################################\n",
        "# here define the folders where the list of files is found\n",
        "# these are text files that contain the list of images, including the full path,  \n",
        "# to be used from each dataset .\n",
        "################################################################\n",
        "\n",
        "# list of images in source dataset\n",
        "image_set_file_s = \\\n",
        "    os.path.join(main_folder_path,\n",
        "                  'labeled_source_images_' +\n",
        "                  args_source + '.txt')\n",
        "# list of labeled images from target dataset (K from each class) used for training\n",
        "image_set_file_t = \\\n",
        "    os.path.join(main_folder_path,\n",
        "                  'labeled_target_images_' +\n",
        "                  args_target + '_%d.txt' % (args_num))\n",
        "# list of labeled images from target dataset (K from each class) used for validation and early stopping\n",
        "image_set_file_t_val = \\\n",
        "    os.path.join(main_folder_path,\n",
        "                  'validation_target_images_' +\n",
        "                  args_target + '_%d.txt'% (args_num))\n",
        "# list of remaining unlabeled images from target dataset \n",
        "image_set_file_unl = \\\n",
        "    os.path.join(main_folder_path,\n",
        "                  'unlabeled_target_images_' +\n",
        "                  args_target + '_%d.txt' % (args_num))\n",
        "    \n",
        "print('image_set_file_s: ' , image_set_file_s)\n",
        "print('image_set_file_t: ' , image_set_file_t)\n",
        "print('image_set_file_t_val: ' , image_set_file_t_val)\n",
        "print('image_set_file_unl: ' , image_set_file_unl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dw6V330qr8k"
      },
      "source": [
        "################################################################\n",
        "# here define the folders where th elist of files is found\n",
        "# these are text files that contain the list of images, including the full path,  \n",
        "# to be used from each dataset .\n",
        "################################################################\n",
        "\n",
        "crop_size = 224\n",
        "\n",
        "class ResizeImage():\n",
        "    def __init__(self, size):\n",
        "        if isinstance(size, int):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        th, tw = self.size\n",
        "        return img.resize((th, tw))\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        ResizeImage(256),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(crop_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        ResizeImage(256),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(crop_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        ResizeImage(256),\n",
        "        transforms.CenterCrop(crop_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print('Source dataset path: ', source_path)\n",
        "source_dataset = Imagelists_VISDA(image_set_file_s, root=source_path,\n",
        "                                  transform=data_transforms['train'])\n",
        "\n",
        "print('Source dataset path: ', target_path)\n",
        "target_dataset = Imagelists_VISDA(image_set_file_t, root=target_path,\n",
        "                                  transform=data_transforms['val'])\n",
        "target_dataset_val = Imagelists_VISDA(image_set_file_t_val, root=target_path,\n",
        "                                      transform=data_transforms['val'])\n",
        "target_dataset_unl = Imagelists_VISDA(image_set_file_unl, root=target_path,\n",
        "                                      transform=data_transforms['val'])\n",
        "target_dataset_test = Imagelists_VISDA(image_set_file_unl, root=target_path,\n",
        "                                        transform=data_transforms['test'])\n",
        "class_list = return_classlist(image_set_file_s)\n",
        "print(\"%d classes in this dataset\" % len(class_list))\n",
        "\n",
        "source_loader = torch.utils.data.DataLoader(source_dataset, batch_size=args_batchsize,\n",
        "                                            num_workers=2, shuffle=True,\n",
        "                                            drop_last=True)\n",
        "target_loader = \\\n",
        "    torch.utils.data.DataLoader(target_dataset,\n",
        "                                batch_size=min(args_batchsize, len(target_dataset)),\n",
        "                                num_workers=2,\n",
        "                                shuffle=True, drop_last=True)\n",
        "target_loader_val = \\\n",
        "    torch.utils.data.DataLoader(target_dataset_val,\n",
        "                                batch_size=min(args_batchsize,\n",
        "                                                len(target_dataset_val)),\n",
        "                                num_workers=2,\n",
        "                                shuffle=True, drop_last=True)\n",
        "target_loader_unl = \\\n",
        "    torch.utils.data.DataLoader(target_dataset_unl,\n",
        "                                batch_size=args_batchsize * 2, num_workers=2,\n",
        "                                shuffle=True, drop_last=True)\n",
        "target_loader_test = \\\n",
        "    torch.utils.data.DataLoader(target_dataset_test,\n",
        "                                batch_size=args_batchsize * 2, num_workers=2,\n",
        "                                shuffle=True, drop_last=True)\n",
        "    \n",
        "\n",
        "# return source_loader, target_loader, target_loader_unl, \\\n",
        "#     target_loader_val, target_loader_test, class_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Ey701vnwgI"
      },
      "source": [
        "\n",
        "use_gpu = torch.cuda.is_available(); print('use_gpu: ' , use_gpu)\n",
        "outputsAndPlots_dir = SSDAN_path+'outputsAndPlots/%s/%s' % (args_dataset, args_method); print(outputsAndPlots_dir)\n",
        "if not os.path.exists(outputsAndPlots_dir):\n",
        "    os.makedirs(outputsAndPlots_dir)\n",
        "outputsAndPlots_file = os.path.join(outputsAndPlots_dir,\n",
        "                           '%s_net_%s_%s_to_%s_num_%s' %\n",
        "                           (args_method, args_net, args_source,\n",
        "                            args_target, args_num))\n",
        "plot_path = outputsAndPlots_file\n",
        "print('plot_path : ' , plot_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M51dTkpS8nJ"
      },
      "source": [
        "\n",
        "#  model_name (str): Name for efficientnet.\n",
        "#             weights_path (None or str):\n",
        "#                 str: path to pretrained weights file on the local disk.\n",
        "#                 None: use pretrained weights downloaded from the Internet.\n",
        "#             advprop (bool):\n",
        "#                 Whether to load pretrained weights\n",
        "#                 trained with advprop (valid when weights_path is None).\n",
        "#             in_channels (int): Input data's channel number.\n",
        "#             num_classes (int):\n",
        "#                 Number of categories for classification.\n",
        "#                 It controls the output size for final linear layer.\n",
        "#             override_params (other key word params):\n",
        "#                 Params to override model's global_params.\n",
        "#                 Optional key:\n",
        "#                     'width_coefficient', 'depth_coefficient',\n",
        "#                     'image_size', 'dropout_rate',\n",
        "#                     'batch_norm_momentum',\n",
        "#                     'batch_norm_epsilon', 'drop_connect_rate',\n",
        "#                     'depth_divisor', 'min_depth'\n",
        "\n",
        "# Define the generator CNN model \"G\", load its pre-trained parameters\n",
        "# then define the predictor F\n",
        "print('args_net: ' , args_net)\n",
        "torch.cuda.manual_seed(args_seed)\n",
        "if args_net == 'resnet34':\n",
        "    G = resnet34()\n",
        "    inc = 512\n",
        "elif args_net == \"EfficientNetBase\":\n",
        "    blocks_args, global_params = efficientnet(width_coefficient=None, depth_coefficient=None, image_size=(256,256,3), dropout_rate=0.2, drop_connect_rate=0.2, num_classes=1000, include_top=False)\n",
        "    G = EfficientNetBase.from_pretrained(model_name='efficientnet-b3',advprop=True)\n",
        "    #G = nn.Sequential(*(list(G1.children())[:-3]))\n",
        "    G.eval()\n",
        "    inc = 1000\n",
        "elif args_net == \"vgg\":\n",
        "    G = VGGBase()\n",
        "    inc = 4096\n",
        "else:\n",
        "    raise ValueError('Model cannot be recognized.')\n",
        "# this code defines a params data structure which contains \n",
        "# parameters like learning rate and weight_decay\n",
        "params = []\n",
        "for key, value in dict(G.named_parameters()).items():\n",
        "    if value.requires_grad:\n",
        "        if 'classifier' not in key:\n",
        "            params += [{'params': [value], 'lr': args_multi,\n",
        "                        'weight_decay': 0.0005}]\n",
        "        else:\n",
        "            params += [{'params': [value], 'lr': args.multi * 10,\n",
        "                        'weight_decay': 0.0005}]\n",
        "# print('params: ' , params)\n",
        "if \"resnet\" in args_net:\n",
        "    F1 = Predictor_deep(num_class=len(class_list), inc=inc)\n",
        "elif \"EfficientNetBase\" in args_net:\n",
        "    F1 = Predictor_deep(num_class=len(class_list), inc=inc)\n",
        "else:\n",
        "    F1 = Predictor(num_class=len(class_list), inc=inc,temp=args_T)\n",
        "\n",
        "weights_init(F1)    # initialize the predictor layer F with random weights\n",
        "G.cuda()           # load model G into CUDA \n",
        "F1.cuda()          # load model G into CUDA "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTJqGGcIRr7X"
      },
      "source": [
        "# this initializes tensor variables\n",
        "\n",
        "im_data_s = torch.FloatTensor(1)\n",
        "im_data_t = torch.FloatTensor(1)\n",
        "im_data_tu = torch.FloatTensor(1)\n",
        "gt_labels_s = torch.LongTensor(1)\n",
        "gt_labels_t = torch.LongTensor(1)\n",
        "sample_labels_t = torch.LongTensor(1)\n",
        "sample_labels_s = torch.LongTensor(1)\n",
        "\n",
        "im_data_s = im_data_s.cuda()\n",
        "im_data_t = im_data_t.cuda()\n",
        "im_data_tu = im_data_tu.cuda()\n",
        "gt_labels_s = gt_labels_s.cuda()\n",
        "gt_labels_t = gt_labels_t.cuda()\n",
        "sample_labels_t = sample_labels_t.cuda()\n",
        "sample_labels_s = sample_labels_s.cuda()\n",
        "\n",
        "im_data_s = Variable(im_data_s)\n",
        "im_data_t = Variable(im_data_t)\n",
        "im_data_tu = Variable(im_data_tu)\n",
        "gt_labels_s = Variable(gt_labels_s)\n",
        "gt_labels_t = Variable(gt_labels_t)\n",
        "sample_labels_t = Variable(sample_labels_t)\n",
        "sample_labels_s = Variable(sample_labels_s)\n",
        "\n",
        "print('creating folder: ' , args_checkpath)\n",
        "if os.path.exists(args_checkpath) == False:\n",
        "    os.mkdir(args_checkpath)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxsbJcysRkvD"
      },
      "source": [
        "\n",
        "def extract_fetures(loader):\n",
        "    G.eval()\n",
        "    F1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    size = 0\n",
        "    num_class = len(class_list)\n",
        "    output_all = np.zeros((0, 512))\n",
        "    gt_all = np.zeros((0))\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    confusion_matrix = torch.zeros(num_class, num_class)\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data_t in enumerate(loader):\n",
        "            with torch.no_grad():\n",
        "               im_data_t.resize_(data_t[0].size()).copy_(data_t[0])\n",
        "               gt_labels_t.resize_(data_t[1].size()).copy_(data_t[1])\n",
        "            feat = G(im_data_t)\n",
        "            output1 = F1.fc1(feat)\n",
        "            output_all = np.r_[output_all, output1.data.cpu().numpy()]\n",
        "            gt_all = np.r_[gt_all, gt_labels_t.data.cpu().numpy()]\n",
        "                    \n",
        "    return output_all, gt_all\n",
        "\n",
        "def test(loader):\n",
        "    G.eval()\n",
        "    F1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    size = 0\n",
        "    num_class = len(class_list)\n",
        "    output_all = np.zeros((0, num_class))\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    confusion_matrix = torch.zeros(num_class, num_class)\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data_t in enumerate(loader):\n",
        "            with torch.no_grad():\n",
        "               im_data_t.resize_(data_t[0].size()).copy_(data_t[0])\n",
        "               gt_labels_t.resize_(data_t[1].size()).copy_(data_t[1])\n",
        "            feat = G(im_data_t)\n",
        "            output1 = F1(feat)\n",
        "            output_all = np.r_[output_all, output1.data.cpu().numpy()]\n",
        "            size += im_data_t.size(0)\n",
        "            pred1 = output1.data.max(1)[1]\n",
        "            for t, p in zip(gt_labels_t.view(-1), pred1.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "            correct += pred1.eq(gt_labels_t.data).cpu().sum()\n",
        "            test_loss += criterion(output1, gt_labels_t) / len(loader)\n",
        "    print('\\nTest set: Average loss: {:.4f}, '\n",
        "          'Accuracy: {}/{} F1 ({:.0f}%)\\n'.\n",
        "          format(test_loss, correct, size,\n",
        "                 100. * correct / size))\n",
        "    return test_loss.data, 100. * float(correct) / size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88cnJ16YpUo2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iaXVTnZuy4R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3EAXj50pS2i"
      },
      "source": [
        "##############################################################\n",
        "#  extract the deatures from the backbone CNN model\n",
        "#  Use t-SNE visualization method to visualize the data distribution\n",
        "#  of the unlabled target samples before we apply SSDAN\n",
        "################################################# \n",
        "\n",
        "out,gt_all= extract_fetures(target_loader_test)\n",
        "print(out.shape)\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.datasets import load_digits\n",
        "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "embeddings = TSNE(n_jobs=4).fit_transform(out)\n",
        "vis_x = embeddings[:, 0]\n",
        "vis_y = embeddings[:, 1]\n",
        "plt.scatter(vis_x, vis_y, c=gt_all, cmap=plt.cm.get_cmap(\"jet\", 12), marker='.')\n",
        "plt.colorbar(ticks=range(12))\n",
        "plt.clim(-0.5, 11.5)\n",
        "plt.xlabel(\"tSNE dim1\")\n",
        "plt.ylabel(\"tSNE dim2\")\n",
        "file_name = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/\"+'tSNE_'+ args_source +'_To_' + args_target +'_before.png'\n",
        "plt.savefig(file_name  , bbox_inches='tight'  , dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVeb6B4OOrJJ"
      },
      "source": [
        "# initilize the model parameters\n",
        "# recall F1 is predictor model \n",
        "# G is feature extractor model using a pretrained CNN\n",
        "\n",
        "lr = args_lr       # define the learning rate\n",
        "\n",
        "def zero_grad_all():    # this function makes the gradient zero\n",
        "    optimizer_g.zero_grad()\n",
        "    optimizer_f.zero_grad()\n",
        "\n",
        "\n",
        "G.train()\n",
        "F1.train()\n",
        "# recall that \"params\" contains parameters such as learning rate and weight_decay\n",
        "optimizer_g = optim.Adam(params,    weight_decay=0.0005)\n",
        "optimizer_f = optim.Adam(list(F1.parameters()), lr=1.0, weight_decay=0.0005)\n",
        "\n",
        "param_lr_g = []\n",
        "for param_group in optimizer_g.param_groups:\n",
        "    param_lr_g.append(param_group[\"lr\"])\n",
        "param_lr_f = []\n",
        "for param_group in optimizer_f.param_groups:\n",
        "    param_lr_f.append(param_group[\"lr\"])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "all_step = args_epochs\n",
        "\n",
        "data_iter_s = iter(source_loader)\n",
        "data_iter_t = iter(target_loader)\n",
        "data_iter_t_unl = iter(target_loader_unl)\n",
        "len_train_source = len(source_loader)\n",
        "len_train_target = len(target_loader)\n",
        "len_train_target_semi = len(target_loader_unl)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWUhpbjnwk1f"
      },
      "source": [
        "# NOW WE START TRAINING\n",
        "\n",
        "start_time = time.process_time()\n",
        "best_acc = 0\n",
        "counter = 0\n",
        "train_losses = []\n",
        "entropy_losses = []\n",
        "tot_loss_test =[]\n",
        "tot_acc_test =[]\n",
        "tot_loss_val=[]\n",
        "tot_acc_val=[]\n",
        "for step in range(all_step): # epochs \n",
        "    # print(step % args_log_interval, (step % args_log_interval) == 0, ' ', end = '')\n",
        "    # make optimizors \n",
        "    optimizer_g = inv_lr_scheduler(param_lr_g, optimizer_g, step,      init_lr=args_lr)\n",
        "    optimizer_f = inv_lr_scheduler(param_lr_f, optimizer_f, step,   init_lr=args_lr)\n",
        "\n",
        "    lr = optimizer_f.param_groups[0]['lr']\n",
        "    if step % len_train_target == 0:\n",
        "        data_iter_t = iter(target_loader)\n",
        "    if step % len_train_target_semi == 0:\n",
        "        data_iter_t_unl = iter(target_loader_unl)\n",
        "    if step % len_train_source == 0:\n",
        "        data_iter_s = iter(source_loader)\n",
        "\n",
        "    data_t = next(data_iter_t)\n",
        "    data_t_unl = next(data_iter_t_unl)\n",
        "    data_s = next(data_iter_s)\n",
        "\n",
        "    # im_data_s.data.resize_(data_s[0].size()).copy_(data_s[0])\n",
        "    # gt_labels_s.data.resize_(data_s[1].size()).copy_(data_s[1])\n",
        "    # im_data_t.data.resize_(data_t[0].size()).copy_(data_t[0])\n",
        "    # gt_labels_t.data.resize_(data_t[1].size()).copy_(data_t[1])\n",
        "    # im_data_tu.data.resize_(data_t_unl[0].size()).copy_(data_t_unl[0])\n",
        "\n",
        "    with torch.no_grad():\n",
        "      im_data_s.resize_(data_s[0].size()).copy_(data_s[0])\n",
        "      gt_labels_s.resize_(data_s[1].size()).copy_(data_s[1])\n",
        "      im_data_t.resize_(data_t[0].size()).copy_(data_t[0])\n",
        "      gt_labels_t.resize_(data_t[1].size()).copy_(data_t[1])\n",
        "      im_data_tu.resize_(data_t_unl[0].size()).copy_(data_t_unl[0])\n",
        "\n",
        "    zero_grad_all() # set gardients to zero, this is our fuction above\n",
        "\n",
        "    data = torch.cat((im_data_s, im_data_t), 0) # concatenate source and target images\n",
        "    #torch.Size([32, 3, 224, 224])\n",
        "    target = torch.cat((gt_labels_s, gt_labels_t), 0)  # concatenate source and target labels\n",
        "    output = G(data)  # apply feature extractor using CNN model\n",
        "    #print(output)\n",
        "    #torch.Size([32, 1000])\n",
        "    \n",
        "    out1 = F1(output)   # apply class predictor\n",
        "\n",
        "    loss = criterion(out1, target)  # compute loss function\n",
        "    loss.backward(retain_graph=True)  # apply a backward pass\n",
        "    optimizer_g.step()   # optimize G - update weights\n",
        "    optimizer_f.step()   # optimize F - update weights\n",
        "\n",
        "    zero_grad_all()  # set gardients to zero, this is our fuction above\n",
        "\n",
        "    if not args_method == 'S+T':\n",
        "        output = G(im_data_tu)\n",
        "        if args_method == 'ENT':\n",
        "            loss_t = entropy(F1, output, args_lamda)\n",
        "            loss_t.backward()\n",
        "            optimizer_f.step()\n",
        "            optimizer_g.step()\n",
        "        elif args_method == 'MME':          \n",
        "            loss_t = adentropy(F1, output, args_lamda)\n",
        "            loss_t.backward()\n",
        "            optimizer_f.step()\n",
        "            optimizer_g.step()\n",
        "        else:\n",
        "            raise ValueError('Method cannot be recognized.')\n",
        "\n",
        "        log_train = 'S {} T {} Train Ep: {} lr{} \\t ' \\\n",
        "                    'Loss Classification: {:.6f} Loss T {:.6f} ' \\\n",
        "                    'Method {}\\n'.format(args_source, args_target,\n",
        "                                          step, lr, loss.data,\n",
        "                                          -loss_t.data, args_method)\n",
        "    else:\n",
        "        log_train = 'S {} T {} Train Ep: {} lr{} \\t ' \\\n",
        "                    'Loss Classification: {:.6f} Method {}\\n'.\\\n",
        "            format(args_source, args_target,\n",
        "                    step, lr, loss.data,\n",
        "                    args_method)\n",
        "    G.zero_grad()\n",
        "    F1.zero_grad()\n",
        "    zero_grad_all()\n",
        "    \n",
        "    train_losses.append(loss.cpu().detach().numpy()) \n",
        "    entropy_losses.append(-loss_t.cpu().detach().numpy())        \n",
        "    if step % args_log_interval == 0 and step > 0:\n",
        "        loss_test, acc_test = test(target_loader_test)\n",
        "        loss_val, acc_val = test(target_loader_val)\n",
        "        tot_loss_test.append(loss_test)\n",
        "        tot_acc_test.append(acc_test)\n",
        "        tot_loss_val.append(loss_val)\n",
        "        tot_acc_val.append(acc_val)\n",
        "        G.train()\n",
        "        F1.train()\n",
        "        if acc_val >= best_acc:\n",
        "            best_acc = acc_val\n",
        "            best_acc_test = acc_test\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "        if args_early:\n",
        "            if counter > args_patience:\n",
        "                break\n",
        "        print(log_train)\n",
        "        print('best acc test %f best acc val %f' % (best_acc_test,best_acc))\n",
        "        # print('outputsAndPlots %s' % outputsAndPlots_file)\n",
        "        with open(outputsAndPlots_file, 'a') as f:\n",
        "            f.write(log_train)\n",
        "            f.write('step %d best test %f validation %f \\n' % (step,\n",
        "                                                      best_acc_test,\n",
        "                                                      best_acc))\n",
        "        G.train()\n",
        "        F1.train()\n",
        "\n",
        "        if args_save_check:\n",
        "            print('saving model')\n",
        "            torch.save(G.state_dict(),\n",
        "                        os.path.join(args_checkpath,\n",
        "                                    \"G_iter_model_{}_{}_\"\n",
        "                                    \"to_{}_step_{}.pth.tar\".\n",
        "                                    format(args_method, args_source,\n",
        "                                            args_target, step)))\n",
        "            torch.save(F1.state_dict(),\n",
        "                        os.path.join(args_checkpath,\n",
        "                                    \"F1_iter_model_{}_{}_\"\n",
        "                                    \"to_{}_step_{}.pth.tar\".\n",
        "                                    format(args_method, args_source,\n",
        "                                            args_target, step)))\n",
        "\n",
        "end_time = time.process_time()\n",
        "print()\n",
        "print('best acc test %f best acc val %f \\n' % (best_acc_test,best_acc))\n",
        "print(\"Process time: \", end_time - start_time)\n",
        "\n",
        "with open(outputsAndPlots_file, 'a') as f:\n",
        "    f.write('best acc test %f best acc val %f \\n' % (best_acc_test,best_acc))\n",
        "    f.write('CPU time: %f \\n' % (end_time - start_time ) )\n",
        "\n",
        "print('saving model')\n",
        "torch.save(G.state_dict(),\n",
        "            os.path.join(args_checkpath,\n",
        "                        \"G_iter_model_{}_{}_\"\n",
        "                        \"to_{}_step_{}.pth.tar\".\n",
        "                        format(args_method, args_source,\n",
        "                                args_target, step)))\n",
        "torch.save(F1.state_dict(),\n",
        "            os.path.join(args_checkpath,\n",
        "                        \"F1_iter_model_{}_{}_\"\n",
        "                        \"to_{}_step_{}.pth.tar\".\n",
        "                        format(args_method, args_source,\n",
        "                                args_target, step)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNogbYMumvlL"
      },
      "source": [
        "# Saving and Loading Models with Shapes\n",
        "# We might want to save the structure of this class together with the model, \n",
        "# in which case we can pass model (and not model.state_dict()) to the saving function:\n",
        "\n",
        "file_name = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/models/G_\"+ args_source +'_To_' + args_target +'.pth'\n",
        "file_name1 = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/models/F1_'+ args_source +'_To_' + args_target +'.pth'\n",
        "# torch.save(G,file_name)\n",
        "# torch.save(F1,file_name1)\n",
        "torch.save(G.state_dict(),file_name)\n",
        "torch.save(F1.state_dict(),file_name1)\n",
        "print(\"Saved PyTorch Model State to\" + file_name)\n",
        "print(\"Saved PyTorch Model State to\" + file_name1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBBeYBbJLvSo"
      },
      "source": [
        "# When loading model weights, we needed to instantiate the model class first, \n",
        "# because the class defines the structure of a network.\n",
        "#We can then load the model like this:\n",
        "file_name = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/models/G_\"+ args_source +'_To_' + args_target +'.pth'\n",
        "file_name1 = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/models/F1_\"+ args_source +'_To_' + args_target +'.pth'\n",
        "G = torch.load(file_name)\n",
        "F1= torch.load(file_name1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mthFUbRkyuK0"
      },
      "source": [
        "#We can then load the model like this:\n",
        "file_name = main_folder_path+\"code/trained_models/test/\"+ args_source +'_To_' + args_target +'.pth'\n",
        "file_name1 = main_folder_path+\"code/trained_models/test/\"+'G_'+ args_source +'_To_' + args_target +'.pth'\n",
        "F1 = torch.load(file_name)\n",
        "G = torch.load(file_name1)\n",
        "G.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVImsjGaq4mw"
      },
      "source": [
        "out,gt_all= extract_fetures(target_loader_test)\n",
        "print(out.shape)\n",
        "\n",
        "embeddings = TSNE(n_jobs=4).fit_transform(out)\n",
        "vis_x = embeddings[:, 0]\n",
        "vis_y = embeddings[:, 1]\n",
        "plt.scatter(vis_x, vis_y, c=gt_all, cmap=plt.cm.get_cmap(\"jet\", 12), marker='.')\n",
        "plt.colorbar(ticks=range(12))\n",
        "plt.clim(-0.5, 11.5)\n",
        "plt.xlabel(\"tSNE dim1\")\n",
        "plt.ylabel(\"tSNE dim2\")\n",
        "file_name = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/\"+'tSNE_'+ args_source +'_To_' + args_target +'_after.png'\n",
        "plt.savefig(file_name  , bbox_inches='tight'  , dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oC3UrJSm5c0"
      },
      "source": [
        "d= {'entropy_losses':entropy_losses, 'train_losses':train_losses}\n",
        "file_name = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/\"+ 'losses_'+ args_source +'_To_' + args_target +'2.npz'\n",
        "np.savez(file_name,**d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZPqLA5noMRd"
      },
      "source": [
        "file_name = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/\"+'losses_'+ args_source +'_To_' + args_target +'2.npz'\n",
        "r= np.load(file_name)\n",
        "r.keys()\n",
        "e1 = r['entropy_losses']\n",
        "t= np.load(file_name)\n",
        "t.keys()\n",
        "tl = t['train_losses']\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.plot(e1,label=\"val\")\n",
        "plt.plot(tl,label=\"train\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBXArL0xY4ZR"
      },
      "source": [
        "file_name_Acc = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/\"+'Acc_'+ args_source +'_To_' + args_target +'2.npz'\n",
        "d= {'tot_acc_test':tot_acc_test, 'tot_acc_val':tot_acc_val}\n",
        "np.savez(file_name_Acc,**d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMZ-rQRHC_oC"
      },
      "source": [
        "file_name_Acc = SSDAN_path+\"outputsAndPlots/plot_5001_epoch/\"+'Acc_'+ args_source +'_To_' + args_target +'2.npz'\n",
        "s= np.load(file_name_Acc)\n",
        "s.keys()\n",
        "a = s['tot_acc_test']\n",
        "k= np.load(file_name_Acc)\n",
        "k.keys()\n",
        "a1 = k['tot_acc_val']\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Training and Validation ACC\")\n",
        "plt.plot(a,label=\"Acc\")\n",
        "plt.plot(a1,label=\"val\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Acc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}